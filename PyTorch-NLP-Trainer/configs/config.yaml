# Working directory
work_dir: 'work_space'

# Model architecture - changed to TextCNN
net_type: 'TextCNN'  # Changed from 'Transformer' to 'TextCNN'
kernel_size: [2, 3, 4, 5]  # Keep kernel sizes for CNN

# Embedding parameters
embed_size: 300  # Reduced from 512 to 300 (better for TextCNN)
context_size: 256  # Reduced context size
dropout: 0.5  # Increased dropout for better regularization
num_channels: 100  # Number of channels for each kernel size

# Training parameters
batch_size: 32  # Increased batch size
num_epochs: 100
lr: 0.001  # Increased learning rate for CNN
optim_type: 'Adam'
weight_decay: 0.0001  # Reduced weight decay

# Learning rate scheduler
milestones: [30, 60, 90]
gamma: 0.1

# Loss function
loss_type: 'CrossEntropyLoss'

# Data parameters
data_type: 'text_dataset'
train_data: 'data/dataset/train'
test_data: 'data/dataset/test'
vocab_file: 'data/dataset/vocab.txt'
class_name: 'data/dataset/class_name.txt'
num_workers: 4
resample: false

# Evaluation
topk: [1, 3, 5]
log_freq: 5
finetune: false
flag: train
gpu_id: [0]